{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_icvbwYpTNRX","outputId":"f3fe9d02-9550-4b7b-8228-cc60dbb75a2f","executionInfo":{"status":"ok","timestamp":1765731423714,"user_tz":-180,"elapsed":1319,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Libraries and paths initialized successfully.\n","Dataset path is: dataset/cropped_objectsV3\n"]}],"source":["# [13]\n","# Core libraries\n","import os\n","import cv2\n","import numpy as np\n","\n","# Machine Learning Libraries\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","import joblib # To save the model\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","DATASET_PATH = 'dataset/cropped_objectsV3'\n","SPLITS = ['train', 'valid', 'test']\n","\n","# Initialize SIFT Detector\n","sift = cv2.SIFT_create()\n","\n","# Define the size of the Visual Vocabulary (K in K-Means)\n","NUM_VISUAL_WORDS = 100\n","\n","print(\"Libraries and paths initialized successfully.\")\n","print(f\"Dataset path is: {DATASET_PATH}\")"]},{"cell_type":"code","source":["import zipfile\n","\n","\n","\n","with zipfile.ZipFile(\"ZIP_cropped_objectsV3.zip\", 'r') as zip_ref:\n","    zip_ref.extractall('dataset')"],"metadata":{"id":"NfAoZbM8Y0NQ","executionInfo":{"status":"ok","timestamp":1765731424164,"user_tz":-180,"elapsed":452,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(\"--- 2.1: Extracting SIFT Descriptors: Collect All Descriptors ---\")\n","all_descriptors = []\n","image_data = [] # To store (filepath, label_id)\n","label_map = {}  # e.g.: {'Road': 0}\n","current_label_id = 0\n","\n","for split in SPLITS:\n","    split_path = os.path.join(DATASET_PATH, split)\n","    if not os.path.exists(split_path):\n","        continue\n","\n","    for object_name in os.listdir(split_path):\n","        object_path = os.path.join(split_path, object_name)\n","        if os.path.isdir(object_path):\n","            # 1. Assign digital label\n","            if object_name not in label_map:\n","                label_map[object_name] = current_label_id\n","                current_label_id += 1\n","            label_id = label_map[object_name]\n","\n","            for filename in os.listdir(object_path):\n","                if filename.endswith(('.jpg', '.jpeg', '.png')):\n","                    filepath = os.path.join(object_path, filename)\n","                    image_data.append((filepath, label_id)) # Store image data\n","\n","                    # 2. Read image in Grayscale\n","                    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n","                    if img is None: continue\n","\n","                    # 3. Extract SIFT features\n","                    kp, des = sift.detectAndCompute(img, None)\n","\n","                    if des is not None:\n","                        all_descriptors.append(des) # Aggregate descriptors\n","\n","# Concatenate all descriptors\n","if all_descriptors:\n","    all_descriptors = np.concatenate(all_descriptors, axis=0).astype(np.float32)\n","    print(f\"Total SIFT descriptors collected: {len(all_descriptors)}\")\n","else:\n","    print(\"Error: No descriptors found. Check path validity and image presence.\")"],"metadata":{"id":"pBpf-oUZUv8e","executionInfo":{"status":"ok","timestamp":1765731424185,"user_tz":-180,"elapsed":4,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d2379b3-9564-40a6-bcd5-b4e402ed70a3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 2.1: Extracting SIFT Descriptors: Collect All Descriptors ---\n","Error: No descriptors found. Check path validity and image presence.\n"]}]},{"cell_type":"code","source":["print(\"--- 2.2: Building Visual Vocabulary using K-Means ---\")\n","\n","# Setup K-Means criteria\n","criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","flags = cv2.KMEANS_RANDOM_CENTERS\n","\n","# Apply K-Means clustering\n","compactness, labels, visual_vocabulary = cv2.kmeans(\n","    all_descriptors,\n","    NUM_VISUAL_WORDS,\n","    None,\n","    criteria,\n","    10,\n","    flags\n",")\n","\n","print(f\"Visual vocabulary built. Shape: {visual_vocabulary.shape}\")"],"metadata":{"id":"9fQlfAfxaS-I","executionInfo":{"status":"error","timestamp":1765731424216,"user_tz":-180,"elapsed":27,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}},"colab":{"base_uri":"https://localhost:8080/","height":280},"outputId":"def819e9-05ea-4b6e-e8fb-1cc14be208df"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 2.2: Building Visual Vocabulary using K-Means ---\n"]},{"output_type":"error","ename":"error","evalue":"OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'kmeans'\n> Overload resolution failed:\n>  - data is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'data'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2792136986.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Apply K-Means clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m compactness, labels, visual_vocabulary = cv2.kmeans(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mall_descriptors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mNUM_VISUAL_WORDS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.12.0) :-1: error: (-5:Bad argument) in function 'kmeans'\n> Overload resolution failed:\n>  - data is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'data'\n"]}]},{"cell_type":"code","source":["print(\"--- 2.3: Creating BoVW Feature Vectors ---\")\n","X = [] # Final feature matrix (BoVW histograms)\n","y = [] # Labels vector\n","\n","for filepath, label_id in image_data:\n","    # 1. Read image and extract descriptors\n","    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n","    if img is None: continue\n","\n","    kp, des = sift.detectAndCompute(img, None)\n","\n","    if des is not None:\n","        # 2. Initialize BoVW Histogram\n","        histogram = np.zeros(visual_vocabulary.shape[0]) # Size = NUM_VISUAL_WORDS (100)\n","\n","        # 3. Assign each descriptor to the closest visual word (Cluster)\n","        for descriptor in des:\n","            descriptor = descriptor.reshape(1, -1)\n","\n","            # Calculate distances to all visual words\n","            distances = np.sqrt(np.sum((visual_vocabulary - descriptor)**2, axis=1))\n","\n","            # Find the closest word\n","            closest_visual_word_index = np.argmin(distances)\n","\n","            # Increment the word count in the histogram\n","            histogram[closest_visual_word_index] += 1\n","\n","        # 4. Normalize the histogram\n","        if np.sum(histogram) > 0:\n","            histogram = histogram / np.sum(histogram) # Normalize so the sum is 1\n","\n","        X.append(histogram)\n","        y.append(label_id)\n","\n","X = np.array(X)\n","y = np.array(y)\n","print(f\"Final feature matrix (Images x Words) shape: {X.shape}\")"],"metadata":{"id":"hYeGKDoEam6f","executionInfo":{"status":"aborted","timestamp":1765731424255,"user_tz":-180,"elapsed":1,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a reverse label map for printing class names\n","class_names = {v: k for k, v in label_map.items()}\n","\n","# Split Data: 80% Training, 20% Testing\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(f\"Training data size (images): {X_train.shape[0]}\")\n","\n","print(\"--- 3.2: Training Random Forest Classifier ---\")\n","\n","# Number of decision trees in the forest (more is generally better but slower)\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n","\n","# Start Training\n","rf_classifier.fit(X_train, y_train)\n","\n","print(\"Random Forest training complete.\")"],"metadata":{"id":"ooEJo1q9axQX","executionInfo":{"status":"aborted","timestamp":1765731424256,"user_tz":-180,"elapsed":2219,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# hyperamters"],"metadata":{"id":"lzlIRFL5lHiE"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","\n","\n","rf = RandomForestClassifier(random_state=42)\n","\n","\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 0.5]\n","}\n","\n","\n","grid_search = GridSearchCV(\n","    estimator=rf,\n","    param_grid=param_grid,\n","    cv=5,\n","    scoring='accuracy',\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","\n","print(\"Starting Grid Search...\")\n","grid_search.fit(X_train, y_train)\n","\n","\n","\n","print(\"-\" * 30)\n","print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n","print(\"Best Hyperparameters Found:\")\n","print(grid_search.best_params_)\n","print(\"-\" * 30)\n","\n","\n","best_rf_model = grid_search.best_estimator_\n"],"metadata":{"id":"xnrX7liElHWz","executionInfo":{"status":"aborted","timestamp":1765731424286,"user_tz":-180,"elapsed":2248,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of decision trees in the forest (Tuned Hyperparameters)\n","rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=4, max_features='sqrt', random_state=42, n_jobs=-1)\n","\n","# Start Training\n","rf_classifier.fit(X_train, y_train)"],"metadata":{"id":"M0ymuJ_CkZNf","executionInfo":{"status":"aborted","timestamp":1765731424295,"user_tz":-180,"elapsed":0,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prediction on the test set\n","y_pred = rf_classifier.predict(X_test)\n","\n","# Calculate overall accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Detailed classification report\n","print(\"\\n--- Detailed Classification Report ---\")\n","target_names = list(class_names.values())\n","print(classification_report(y_test, y_pred, target_names=target_names))\n","\n","# Create Confusion Matrix\n","conf_mat = confusion_matrix(y_test, y_pred)\n","\n","# Visualize the Matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(\n","    conf_mat,\n","    annot=True,\n","    fmt='d',\n","    cmap='Blues',\n","    xticklabels=target_names,\n","    yticklabels=target_names\n",")\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix for Random Forests')\n","plt.show()\n","\n","# 5.1 Save Random Forest Classifier Model\n","joblib.dump(rf_classifier, 'random_forest_sift_model.joblib')\n","print(\"Random Forest model saved.\")\n","\n","# 5.2 Save Visual Vocabulary (You need this to convert any new image into a feature vector)\n","np.save('visual_vocabulary.npy', visual_vocabulary)\n","print(\"Visual vocabulary saved.\")"],"metadata":{"id":"opdMbpChe8h7","executionInfo":{"status":"aborted","timestamp":1765731424296,"user_tz":-180,"elapsed":0,"user":{"displayName":"Aymen Slimani","userId":"12764299755831774450"}}},"execution_count":null,"outputs":[]}]}